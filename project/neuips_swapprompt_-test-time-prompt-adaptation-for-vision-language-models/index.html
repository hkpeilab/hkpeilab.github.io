<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.0.0-beta.3 for Hugo"><meta name=description content="In this paper, we propose SwapPrompt, a novel framework that can effectively leverage the self-supervised contrastive learning to facilitate the test-time prompt adaptation. SwapPrompt employs a dual prompts paradigm, i.e., an online prompt and a target prompt that averaged from the online prompt to retain historical information."><link rel=alternate hreflang=en-us href=https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload="this.media='all'"><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'"><link rel=stylesheet href=/css/wowchemy.14ed061da97974d1963d99308520201c.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hub8bd7c1267eb57500e77bce8d727c229_911772_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/media/icon_hub8bd7c1267eb57500e77bce8d727c229_911772_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="PEILab"><meta property="og:url" content="https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/"><meta property="og:title" content="(NeurIPS2023) SwapPrompt:Test-Time Prompt Adaptation for Vision-Language Models | PEILab"><meta property="og:description" content="In this paper, we propose SwapPrompt, a novel framework that can effectively leverage the self-supervised contrastive learning to facilitate the test-time prompt adaptation. SwapPrompt employs a dual prompts paradigm, i.e., an online prompt and a target prompt that averaged from the online prompt to retain historical information."><meta property="og:image" content="https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/featured.png"><meta property="twitter:image" content="https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-09-22T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-26T23:08:50+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/"},"headline":"(NeurIPS2023) SwapPrompt:Test-Time Prompt Adaptation for Vision-Language Models","image":["https://hkpeilab.netlify.app/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/featured.png"],"datePublished":"2023-09-22T00:00:00Z","dateModified":"2024-06-26T23:08:50+08:00","author":{"@type":"Person","name":"Authors"},"publisher":{"@type":"Organization","name":"PEILab","logo":{"@type":"ImageObject","url":"https://hkpeilab.netlify.app/media/logo_hu327f33d11c6af42c6fedb6aa301ebf3b_346233_192x192_fit_lanczos_2.png"}},"description":"In this paper, we propose SwapPrompt, a novel framework that can effectively leverage the self-supervised contrastive learning to facilitate the test-time prompt adaptation. SwapPrompt employs a dual prompts paradigm, i.e., an online prompt and a target prompt that averaged from the online prompt to retain historical information."}</script><title>(NeurIPS2023) SwapPrompt:Test-Time Prompt Adaptation for Vision-Language Models | PEILab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=14684923b6855e59c570316699658df3><script src=/js/wowchemy-init.min.b024895df05e271929739bb54886c674.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/media/logo_hu327f33d11c6af42c6fedb6aa301ebf3b_346233_0x70_resize_lanczos_2.png alt=PEILab></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/media/logo_hu327f33d11c6af42c6fedb6aa301ebf3b_346233_0x70_resize_lanczos_2.png alt=PEILab></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/research><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/demos><span>Demos</span></a></li><li class=nav-item><a class=nav-link href=/post><span>News</span></a></li><li class=nav-item><a class=nav-link href=/gallery><span>Gallery</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><article class="article article-project"><div class="article-container pt-3"><h1>(NeurIPS2023) SwapPrompt:Test-Time Prompt Adaptation for Vision-Language Models</h1><div class=article-metadata><span class=article-date>Last updated on
Jun 26, 2024</span></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:209px><div style=position:relative><img src=/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/featured_huc8acb8afcfcafb90c55caa0e30069a0f_416856_720x0_resize_lanczos_2.png alt class=featured-image></div></div><div class=article-container><div class=article-style><p>In this paper, we propose SwapPrompt, a novel framework that can effectively leverage the self-supervised contrastive learning to facilitate the test-time prompt adaptation. SwapPrompt employs a dual prompts paradigm, i.e., an online prompt and a target prompt that averaged from the online prompt to retain historical information. In addition, SwapPrompt applies a swapped prediction mechanism, which takes advantage of the representation capabilities of pre-trained models to enhance the online prompt via contrastive learning.</p><h2 id=abstract-overview>Abstract Overview</h2><p>Test-time adaptation (TTA) is a special and practical setting in unsupervised domain adaptation, which allows a pre-trained model in a source domain to adapt to unlabeled test data in another target domain. To avoid the computation-intensive backbone fine-tuning process, the zero-shot generalization potentials of the emerging pre-trained vision-language models (e.g., CLIP, CoOp) are leveraged to only tune the run-time prompt for unseen test domains. However, existing solutions have yet to fully exploit the representation capabilities of pre-trained models as they only focus on the entropy-based optimization and the performance is far below the supervised prompt adaptation methods, e.g., CoOp. In this paper, we propose SwapPrompt, a novel framework that can effectively leverage the self-supervised contrastive learning to facilitate the test-time prompt adaptation. SwapPrompt employs a dual prompts paradigm, i.e., an online prompt and a target prompt that averaged from the online prompt to retain historical information. In addition, SwapPrompt applies a swapped prediction mechanism, which takes advantage of the representation capabilities of pre-trained models to enhance the online prompt via contrastive learning. Specifically, we use the online prompt together with an augmented view of the input image to predict the class assignment generated by the target prompt together with an alternative augmented view of the same image. The proposed SwapPrompt can be easily deployed on vision-language models without additional requirement, and experimental results show that it achieves state-ofthe-art test-time adaptation performance on ImageNet and nine other datasets. It is also shown that SwapPrompt can even achieve comparable performance with supervised prompt adaptation methods.</p><p>More information refer to <a href=https://papers.neurips.cc/paper_files/paper/2023/file/cdd0640218a27e9e2c0e52e324e25db0-Paper-Conference.pdf target=_blank rel=noopener>SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models, NeurIPS2023</a></p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt srcset="/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/1_huf9a71ac00840b8185050b00ce41c5dfe_356808_09653dd5a71dcb34302cebf14d7a04ed.png 400w,
/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/1_huf9a71ac00840b8185050b00ce41c5dfe_356808_acf98489e144bcfffcead1eb0893da55.png 760w,
/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/1_huf9a71ac00840b8185050b00ce41c5dfe_356808_1200x1200_fit_lanczos_2.png 1200w" src=/project/neuips_swapprompt_-test-time-prompt-adaptation-for-vision-language-models/1_huf9a71ac00840b8185050b00ce41c5dfe_356808_09653dd5a71dcb34302cebf14d7a04ed.png width=760 height=198 loading=lazy data-zoomable></div></div></figure></div><div class=article-tags><a class="badge badge-light" href=/tags/foundation-model/>Foundation Model</a></div><div class="project-related-pages content-widget-hr"></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Copyright © The Pervasive Edge Intelligence Laboratory Reserved. 2025</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/_vendor/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.e844b7881168826667ba422c36255a69.js></script><script async defer src=https://buttons.github.io/buttons.js></script></body></html>