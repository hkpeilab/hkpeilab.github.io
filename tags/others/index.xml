<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Others | PEILab</title><link>https://hkpeilab.netlify.app/tags/others/</link><atom:link href="https://hkpeilab.netlify.app/tags/others/index.xml" rel="self" type="application/rss+xml"/><description>Others</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Copyright Â© The Pervasive Edge Intelligence Laboratory Reserved. 2025</copyright><lastBuildDate>Fri, 01 Sep 2023 00:00:00 +0000</lastBuildDate><image><url>https://hkpeilab.netlify.app/media/logo_hu327f33d11c6af42c6fedb6aa301ebf3b_346233_300x300_fit_lanczos_2.png</url><title>Others</title><link>https://hkpeilab.netlify.app/tags/others/</link></image><item><title>(KDD2023) Investigating Trojan Attacks on Pre-trained Language Model-powered Database Middleware</title><link>https://hkpeilab.netlify.app/project/kdd_investigating-trojan-attacks-on-pre-trained-language-model-powered-database-middleware/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/kdd_investigating-trojan-attacks-on-pre-trained-language-model-powered-database-middleware/</guid><description>&lt;p>The recent success of pre-trained language models (PLMs) such as BERT has resulted in the development of various beneficial database middlewares, including natural language query interfaces and entity matching. This shift has been greatly facilitated by the extensive external knowledge of PLMs. However, as PLMs are often provided by untrusted third parties, their lack of standardization and regulation poses significant security risks that have yet to be fully explored. This paper investigates the security threats posed by malicious PLMs to these emerging database middlewares. We specifically propose a novel type of Trojan attack, where a maliciously designed PLM causes unexpected behavior in the database middleware. These Trojan attacks possess the following characteristics: (1) Triggerability: The Trojan-infected database middleware will function normally with normal input, but will likely malfunction when triggered by the attacker. (2) Imperceptibility: There is no need for noticeable modification of the input to trigger the Trojan. (3) Generalizability: The Trojan is capable of targeting a variety of downstream tasks, not just one specific task. We thoroughly evaluate the impact of these Trojan attacks through experiments and analyze potential countermeasures and their limitations. Our findings could aid in the creation of stronger mechanisms for the implementation of PLMs in database middleware.&lt;/p></description></item><item><title>(ATC2021) Adaptive Quantization-aware Training and Model Compression.</title><link>https://hkpeilab.netlify.app/project/r1-adaptive-qat/</link><pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/r1-adaptive-qat/</guid><description>&lt;h3 id="research-opportunity-1-adaptive-quantization-aware-training-and-model-compression">Research Opportunity 1: Adaptive Quantization-aware Training and Model Compression&lt;/h3>
&lt;p>&lt;strong>Illustration:&lt;/strong> On-device learning is an emerging technique to pave the last mile of enabling edge intelligence, which eliminates the limitations of conventional in-cloud computing where dozens of computational capacities and memories are needed. A high- performance on-device learning system requires breaking the constraints of limited resources and alleviating computational overhead. Our preliminary work shows that employing the 8-bit fixed-point (INT8) quantization in both forward and back- ward passes over a deep model is a promising way to enable tiny on-device learning in practice. The key to an efficient quantization-aware training (QAT) method is to exploit the hardware- level enabled acceleration while preserving the training quality in each layer. However, off-the-shelf quantization methods cannot handle the on-device learning paradigm of fixed-point processing. To overcome these challenges, we propose to design an adaptive QAT algorithm, which jointly optimizes the computation of forward and backward passes. Besides, we need to build efficient network components to automatically counteract the quantization error of tensor arithmetic. We intend to implement our methods in Octo, a lightweight cross-platform system for tiny on-device learning, and keep improving its performance to support more realistic applications.&lt;/p></description></item><item><title>(NeurIPS2022) Progressive Network Sparsification and Latent Feature Compression for Scalable Collaborative Learning.</title><link>https://hkpeilab.netlify.app/project/r4-progressive-feature-compression/</link><pubDate>Fri, 15 Apr 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/r4-progressive-feature-compression/</guid><description>&lt;h3 id="research-opportunity-4-progressive-network-sparsification-and-latent-feature-compression-for-scalable-collaborative-learning">Research Opportunity 4: Progressive Network Sparsification and Latent Feature Compression for Scalable Collaborative Learning&lt;/h3>
&lt;p>&lt;strong>Illustration:&lt;/strong> In the edge intelligence environment, new data is continuously generated on user devices that cannot be aggregated at once due to privacy and energy concerns. These issues require us to develop new insights into traffic saving to build a communication-efficient collaborative learning paradigm. Unlike previous methods aiming at improving bandwidth utilization or using an unstructured pixel-wise compression, we jointly capture the channel and spatial-level feature redundancy, and conduct a hierarchical compression in these two levels to achieve a much higher traffic reduction ratio. Specifically, we need to design a more efficient feature compression method to leverage the pixel similarity, and reorganize the features into groups based on channel significance to prune the network. Meanwhile, we intend to calibrate the gradients of compressed features with a comprehensive theoretical analysis of the convergence rate. Such a co-design can provide a significant traffic reduction over existing methods while not sacrificing much model accuracy, achieving good training flexibility and communicational efficiency. We believe this work can contribute to the further development of edge intelligence applications.&lt;/p></description></item><item><title>(AAAI2023)Masked Autoencoders for Occlusion-aware Visual Learners</title><link>https://hkpeilab.netlify.app/project/r5-visual-anti-occlusion/</link><pubDate>Thu, 14 Apr 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/r5-visual-anti-occlusion/</guid><description>&lt;h3 id="research-opportunity-5-masked-autoencoders-for-occlusion-aware-visual-learners">Research Opportunity 5: Masked Autoencoders for Occlusion-aware Visual Learners&lt;/h3>
&lt;p>&lt;strong>Illustration:&lt;/strong> Recent years have witnessed learning-based video perception algorithms getting popular in more scenarios with occlusions, where invisible areas for perception objects significantly affect accuracy. Existing methods mainly use convolutional neural networks as the backbone and get limited local features to recover the occluded part. Such an anti-occlusion pipeline often suffers from the challenges of self-occlusion scenery, where similar parts of occluders and occludes are ambiguous. In this case, we need to design a masked visual autoencoder for image processing and video streaming, which recovers occluded regions by extracting deep spatial information at a higher semantic level. This autoencoder can get better details inferred from global self-attention and thus improves accuracy. The gist is to train the autoencoder to extract key-point information from the key patches that are manually masked in a self-supervised manner to simulate the occlusion in video streaming. To choose the patches that should be masked, we design a high-capacity learnable gate that can extract contrastive representation, i.e., distinguish important feature regions and background regions, to generate a binary mask by randomly choosing a part of feature patches. We also propose an end-to-end pipeline for training and inference, which can effectively reduce the dependency of annotated occluded datasets and can be further applied to other visual tasks. This pipeline can obtain a great computation saving with much fewer annotated datasets, and hold a higher runtime performance over the SOTA ViT methods.&lt;/p></description></item><item><title>Masked Autoencoders for Occlusion-aware Visual Learners</title><link>https://hkpeilab.netlify.app/pages/intro/</link><pubDate>Thu, 14 Apr 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/pages/intro/</guid><description>&lt;ul>
&lt;li>&lt;strong>Cloud-Edge Collaborative Large Models:&lt;/strong> We focus on building open, intelligent, and efficient AI large models that cater to the diverse data and resources distributed across edge endpoints. Our goal is to satisfy the multi-faceted demands of large model training, fine-tuning, inference, and deployment, while optimizing the model construction process through intelligent means to enhance performance. We aim to drive the widespread adoption of AIGC in vertical application scenarios, achieving deep technology integration and maximum value creation.&lt;/li>
&lt;li>&lt;strong>AI Computing Cyberinfrastructure:&lt;/strong> We are building a federated edge intelligence platform tailored for large models, leveraging our &amp;lsquo;algorithm-network-intelligence&amp;rsquo; integrated technology to design algorithms that adapt large models to edge environments based on &amp;lsquo;hybrid expert models&amp;rsquo;. By harnessing edge computing network technology, we integrate fragmented computing resources at the edge, enabling large models to run on edge devices and supporting various generative AI capabilities. This will reduce hardware costs and expand the spatiotemporal scope of large model services.&lt;/li>
&lt;li>&lt;strong>Trustworthy AI Governance:&lt;/strong> As large models are increasingly deployed, their security concerns are becoming more pronounced. We are committed to researching the security challenges faced by large models, including data poisoning and adversarial attacks, with the goal of building secure, trustworthy, and robust AI models that promote the development of trustworthy AI governance.&lt;/li>
&lt;li>&lt;strong>AI4Science:&lt;/strong> AI technology has made breakthroughs in challenging tasks such as weather forecasting. We focus on training and developing ultra-high-resolution meteorological large models driven by data, as well as researching AI assimilation algorithms and extreme disaster prediction (e.g., FengWu-GHR), contributing to the advancement of scientific research.&lt;/li>
&lt;/ul></description></item><item><title>(TKDE)Semantic Query and Index Layer in Semantic Blockchain Database</title><link>https://hkpeilab.netlify.app/project/semantic-blockchain-database/</link><pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/semantic-blockchain-database/</guid><description>&lt;h2 id="background">Background&lt;/h2>
&lt;p>Blockchain database is a new direction that constructs index on top of blockchain to provide rich query functionalities. The existing works are either insecure because the query process separates from the blockchain consensus, or inscalable because all the data needs to be stored in the block. Therefore, we propose an authenticated semantic database layer for blockchains. We design a hybrid on/off chain blockchain storage architecture in which the majority of blockchain storage is offloaded to the off-chain storage and a novel index structure named Merkle Semantic Trie (MST) is designed to be a secure and semantic bridge between on- and off-chain. Based on MST, MSTDB provides a variety of semantic query functions including multi-keyword query, range query, Top-K query, and cross-chain query. Besides, to improve the performance further, we design some index compression and query preprocessing techniques for our semantic database layer.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>An Efficient Query Scheme for Hybrid Storage Blockchains based on Merkle Semantic Trie, Best Paper Award Runner Up received in SRDS 2020 (CCF-B).&lt;/p></description></item><item><title>(ICPP2020)Intelligent Consensus Layer in Learning-Driven Dynamic Architecture</title><link>https://hkpeilab.netlify.app/project/intelligent-consensus-layer/</link><pubDate>Wed, 16 Mar 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/intelligent-consensus-layer/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Most existing blockchain systems adopt a static policy that cannot efciently deal with the dynamic environment in the blockchain system, i.e., joining and leaving of nodes, and malicious attack. Therefore, we propose a novel dynamic sharding-based blockchain framework to achieve a good balance between performance and security without compromising scalability under a dynamic environment. For the framework, a deep reinforcement learning (DRL)-based consensus is designed to acquire optimal sharding policies in a series of dynamic and high-dimensional environment states.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>SkyChain: A Deep Reinforcement Learning-Empowered Dynamic Blockchain Sharding System, Best Paper Award Runner Up received in ICPP 2020 (CCF-B).&lt;/p></description></item><item><title>(INFOCOM2021)Layered Sharding Architecture for Blockchain</title><link>https://hkpeilab.netlify.app/project/scalable-consensus-layer/</link><pubDate>Mon, 14 Mar 2022 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/scalable-consensus-layer/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>As a promising solution to blockchain scalability, sharding divides blockchain nodes into small groups called shards, splitting the workload. Existing works for sharding, however, are limited by cross-shard transactions, since they need to split each cross-shard transaction into multiple sub-transactions, each of which costs a consensus round to commit. To deal with the serious performance degradation brought by cross-shard transactions. Therefore, we propose a novel layered sharding architecture for blockchain and a cooperation-based layered sharding consensus. The basic idea is to allow shards to overlap, rather than isolating them completely, so that some nodes can locate in more than one shard. For cross-shard transactions, nodes located in the overlap of these shards can cooperative to verify, process and commit them directly and efficiently.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>Pyramid: A Layered Sharding Blockchain System, INFOCOM 2021 (CCF-A).&lt;/p></description></item><item><title>(INFOCOM2021)New Architectures and Methodologies for High Performance Sharding Blockchain</title><link>https://hkpeilab.netlify.app/project/new-architectures-and-methodologies-for-high-performance-sharding-blockchain/</link><pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate><guid>https://hkpeilab.netlify.app/project/new-architectures-and-methodologies-for-high-performance-sharding-blockchain/</guid><description>&lt;p>Blockchain draws tremendous attention from academia and industry, since it can provide distributed ledgers with data transparency, integrity, and immutability to untrusted parties for various decentralized applications. However, it is still challenging for blockchain to deal with large-scale networks because of the limited scalability of the blockchain systems. Sharding is a novel blockchain architecture that is proved to significantly improve the scalability of blockchain. Its main idea is to divide blockchain nodes into small groups called shards, which can handle transactions in parallel. To exploit the shortages of blockchain sharding for real application environment, we conduct two research projects as follows.&lt;/p>
&lt;p>First, to deal with the serious performance degradation brought by cross-shard transactions, we propose a novel layered sharding architecture for blockchain and a cooperation-based layered sharding consensus. The basic idea is to allow shards to overlap, rather than isolating them completely, so that some nodes can locate in more than one shard. For cross-shard transactions, nodes located in the overlap of these shards can cooperative to verify, process and commit them directly and efficiently.&lt;/p>
&lt;figure id="figure-blockchain-and-training">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >
&lt;img alt="Blockchain and Training"
src="https://hkpeilab.netlify.app/project/new-architectures-and-methodologies-for-high-performance-sharding-blockchain/picture1.svg"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Blockchain and Training
&lt;/figcaption>&lt;/figure>
&lt;p>Second, most existing blockchain sharding systems adopt a static sharding policy that cannot efciently deal with the dynamic environment in the blockchain system, i.e., joining and leaving of nodes, and malicious attack. We propose a novel dynamic sharding-based blockchain framework to achieve a good balance between performance and security without compromising scalability under a dynamic environment. For the framework, a deep reinforcement learning (DRL)-based consensus is designed to acquire optimal sharding policies in a series of dynamic and high-dimensional environment states.&lt;/p></description></item></channel></rss>